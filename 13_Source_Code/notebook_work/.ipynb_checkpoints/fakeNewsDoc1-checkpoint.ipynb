{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5c6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "data = pd.read_csv('dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d3d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64806703",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['total'] = data['title'] + data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ca837",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    filter_sentence = ''\n",
    "    \n",
    "    sentence = row['total']\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "\n",
    "    for w in words:\n",
    "        filter_sentence = filter_sentence + ' ' + str(lemmatizer.lemmatize(w)).lower()\n",
    "\n",
    "        data.loc[index, 'total'] = filter_sentence\n",
    "\n",
    "data = data[['total','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7ee837",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e27c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['total']\n",
    "Y = data['label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cf45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d562119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tranforming data to value using CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "count_vectorizer.fit(x_train)\n",
    "X_freqMatrix = count_vectorizer.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1175e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying TFIDF to result obtained after Counvectorizer\n",
    "\n",
    "tfidf = TfidfTransformer(norm='l2')\n",
    "x_train = tfidf.fit_transform(X_freqMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52002c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying feature extraction to test data too\n",
    "\n",
    "X_test_freqMatrix = count_vectorizer.transform(x_test)\n",
    "x_test = tfidf.transform(X_test_freqMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b9fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026c8100",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ed38a",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb3acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "logreg = LogisticRegression(C=1e5, solver='lbfgs', max_iter=1000000)\n",
    "logreg.fit(x_train, y_train)\n",
    "predicted = logreg.predict(x_test)\n",
    "print( \"Accuracy Percentage {:.2f}\".format(logreg.score(x_test, y_test)) )\n",
    "cm = confusion_matrix(y_test, predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416c3889",
   "metadata": {},
   "source": [
    "### MultiNomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)\n",
    "predicted = nb.predict(x_test)\n",
    "print( \"Accuracy Percentage {:.2f}\".format(nb.score(x_test, y_test)) )\n",
    "cm = confusion_matrix(y_test, predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0f24a5",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a11eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)\n",
    "predicted = rf.predict(x_test)\n",
    "print( \"Accuracy Percentage {:.2f}\".format(rf.score(x_test, y_test)) )\n",
    "cm = confusion_matrix(y_test, predicted)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764650fe",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataframe.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train, test = train_test_split(data, test_size=0.3)\n",
    "\n",
    "train['total'] = train['title'] + train['text']\n",
    "test['total'] = test['title'] + test['text']\n",
    "\n",
    "for index, row in train.iterrows():\n",
    "    filter_sentence = ''\n",
    "    \n",
    "    sentence = row['total']\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "\n",
    "    for w in words:\n",
    "        filter_sentence = filter_sentence + ' ' + str(lemmatizer.lemmatize(w)).lower()\n",
    "\n",
    "        train.loc[index, 'total'] = filter_sentence\n",
    "\n",
    "train = train[['total','label']]\n",
    "\n",
    "X_train = train['total']\n",
    "Y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer(norm='l2')),\n",
    "    ('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a2526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the pipeline\n",
    "\n",
    "filename = 'pipeline.sav'\n",
    "joblib.dump(pipeline, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c6e816",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './pipeline.sav'\n",
    "\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.predict([\"flynn hillary clinton big woman campus breitbart daniel j flynnever get feeling life circle roundabout rather head straight line toward intended destination hillary clinton remains big woman campus leafy liberal wellesley massachusetts everywhere else vote likely inauguration dress remainder day way miss havisham forever wore wedding dress speaking great expectations hillary rodham overflowed 48 year ago first addressed wellesley graduating class the president college informed gathered 1969 student needed debate far i could ascertain spokesman kind like democratic primary 2016 minus term unknown even seven sisters school i glad miss adams made clear i speaking today u 400 u miss rodham told classmate after appointing edger bergen charlie mccarthys mortimer snerds attendance bespectacled granny glass awarding matronly wisdom least john lennon wisdom took issue previous speaker despite becoming first win election seat u s senate since reconstruction edward brooke came criticism calling empathy goal protestors criticized tactic though clinton senior thesis saul alinsky lamented black power demagogue elitist arrogance repressive intolerance within new left similar word coming republican necessitated brief rebuttal trust rodham ironically observed 1969 one word i asked class rehearsal wanted say everyone came said talk trust talk lack trust u way feel others talk trust bust what say what say feeling permeates generation perhaps even understood distrusted the trust bust certainly busted clintons 2016 plan she certainly even understand people distrusted after whitewater travelgate vast conspiracy benghazi missing email clinton found distrusted voice friday there load compromising road broadening political horizon and distrust american people trump edged 48 percent 38 percent question immediately prior novembers election stood major reason closing horizon clinton described vanquisher supporter embracing lie con alternative fact assault truth reason she failed explain american people chose lie truth as history major among today know well people power invent fact attack question mark beginning end free society offered that hyperbole like many people emerge 1960s hillary clinton embarked upon long strange trip from high school goldwater girl wellesley college republican president democratic politician clinton drank time place gave degree more significantly went idealist cynic comparison two wellesley commencement address show way back lamented long leader viewed politics art possible challenge practice politics art making appears impossible possible now big woman campus odd woman white house wonder current station even possible why arent i 50 point ahead asked september in may asks isnt president the woman famously dubbed congenital liar bill safire concludes lie mind getting stood election day like finding jilted bride wedding day inspires dangerous delusion\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3fe116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
